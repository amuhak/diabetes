{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-09T16:26:56.035290800Z",
     "start_time": "2023-11-09T16:26:50.708069900Z"
    }
   },
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/datasets/alexteboul/diabetes-health-indicators-DATASET\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47ebda541a3c4457",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T16:26:56.056155400Z",
     "start_time": "2023-11-09T16:26:56.048997300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Gpu\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Found Gpu\" if torch.cuda.is_available() else \"No Gpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5647b46ae990b9f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T16:26:56.262552800Z",
     "start_time": "2023-11-09T16:26:56.097180400Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the CSV files into pandas DataFrames\n",
    "data = pd.read_csv(\"merged.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75d3bfc0b717387d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T16:26:56.280482400Z",
     "start_time": "2023-11-09T16:26:56.262552800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   Diabetes_binary  HighBP  HighChol  CholCheck   BMI  Smoker  Stroke  \\\n0              0.0     1.0       0.0        1.0  26.0     0.0     0.0   \n1              0.0     1.0       1.0        1.0  26.0     1.0     1.0   \n2              0.0     0.0       0.0        1.0  26.0     0.0     0.0   \n3              0.0     1.0       1.0        1.0  28.0     1.0     0.0   \n4              0.0     0.0       0.0        1.0  29.0     1.0     0.0   \n\n   HeartDiseaseorAttack  PhysActivity  Fruits  ...  AnyHealthcare  \\\n0                   0.0           1.0     0.0  ...            1.0   \n1                   0.0           0.0     1.0  ...            1.0   \n2                   0.0           1.0     1.0  ...            1.0   \n3                   0.0           1.0     1.0  ...            1.0   \n4                   0.0           1.0     1.0  ...            1.0   \n\n   NoDocbcCost  GenHlth  MentHlth  PhysHlth  DiffWalk  Sex   Age  Education  \\\n0          0.0      3.0       5.0      30.0       0.0  1.0   4.0        6.0   \n1          0.0      3.0       0.0       0.0       0.0  1.0  12.0        6.0   \n2          0.0      1.0       0.0      10.0       0.0  1.0  13.0        6.0   \n3          0.0      3.0       0.0       3.0       0.0  1.0  11.0        6.0   \n4          0.0      2.0       0.0       0.0       0.0  0.0   8.0        5.0   \n\n   Income  \n0     8.0  \n1     8.0  \n2     8.0  \n3     8.0  \n4     8.0  \n\n[5 rows x 22 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Diabetes_binary</th>\n      <th>HighBP</th>\n      <th>HighChol</th>\n      <th>CholCheck</th>\n      <th>BMI</th>\n      <th>Smoker</th>\n      <th>Stroke</th>\n      <th>HeartDiseaseorAttack</th>\n      <th>PhysActivity</th>\n      <th>Fruits</th>\n      <th>...</th>\n      <th>AnyHealthcare</th>\n      <th>NoDocbcCost</th>\n      <th>GenHlth</th>\n      <th>MentHlth</th>\n      <th>PhysHlth</th>\n      <th>DiffWalk</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>Education</th>\n      <th>Income</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>26.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>5.0</td>\n      <td>30.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>6.0</td>\n      <td>8.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>26.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>12.0</td>\n      <td>6.0</td>\n      <td>8.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>26.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>10.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>13.0</td>\n      <td>6.0</td>\n      <td>8.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>28.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>11.0</td>\n      <td>6.0</td>\n      <td>8.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>29.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>8.0</td>\n      <td>5.0</td>\n      <td>8.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 22 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Print the first 5 rows of the DataFrame\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b119f016e742740",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T16:26:56.311432800Z",
     "start_time": "2023-11-09T16:26:56.303331200Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the model\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(21, 64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(64, 256)\n",
    "        self.fc3 = nn.Linear(256, 1024)\n",
    "        self.batchnorm = nn.BatchNorm1d(1024)\n",
    "        self.fc5 = nn.Linear(1024, 256)\n",
    "        self.dropout = nn.Dropout(0.50)\n",
    "        self.fc6 = nn.Linear(256, 2)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.batchnorm(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc5(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc6(x)\n",
    "        x = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13fa9734c4afe2ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T16:26:56.438053400Z",
     "start_time": "2023-11-09T16:26:56.311432800Z"
    }
   },
   "outputs": [],
   "source": [
    "# Scale and process the data\n",
    "scaler = StandardScaler()\n",
    "# X = data.drop('Diabetes_binary', axis=1)\n",
    "df = data\n",
    "scaled_data = scaler.fit_transform(df)\n",
    "scaled_df = pd.DataFrame(scaled_data, columns=df.columns)\n",
    "X = scaled_df.drop(\"Diabetes_binary\", axis=1)\n",
    "Y = data[\"Diabetes_binary\"]\n",
    "del df, scaled_data, scaled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c2b1256b8c12539",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T16:26:56.440569400Z",
     "start_time": "2023-11-09T16:26:56.352669600Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, Y, test_size=0.2, random_state=3, stratify=Y, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "365ea4a42b250b1d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T16:26:56.441076100Z",
     "start_time": "2023-11-09T16:26:56.384236Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the X_train (56553, 21)\n",
      "Shape of the y_train (56553,)\n",
      "Shape of the X_test (14139, 21)\n",
      "Shape of the y_test (14139,)\n"
     ]
    }
   ],
   "source": [
    "# Print the shapes of the train and test sets\n",
    "print(\"Shape of the X_train {}\".format(X_train.shape))\n",
    "print(\"Shape of the y_train {}\".format(y_train.shape))\n",
    "print(\"Shape of the X_test {}\".format(X_test.shape))\n",
    "print(\"Shape of the y_test {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d4a1678ab29d7a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T16:26:56.441592800Z",
     "start_time": "2023-11-09T16:26:56.392241300Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert the train and test sets into numpy arrays\n",
    "X_train_array = X_train.to_numpy()\n",
    "y_train_array = y_train.to_numpy()\n",
    "X_test_array = X_test.to_numpy()\n",
    "y_test_array = y_test.to_numpy()\n",
    "# Convert the numpy arrays into PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train_array, dtype=torch.float32).to(device)\n",
    "y_train_tensor = torch.tensor(y_train_array, dtype=torch.long).to(device)\n",
    "X_test_tensor = torch.tensor(X_test_array, dtype=torch.float32).to(device)\n",
    "y_test_tensor = torch.tensor(y_test_array, dtype=torch.long).to(device)\n",
    "#del X_train_array, y_train_array, X_test_array, y_test_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "830acf3abf660d34",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T16:27:00.628763300Z",
     "start_time": "2023-11-09T16:26:56.424864100Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-09 11:07:22.805847: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-09 11:07:25.734634: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "# Define the model, optimizer and loss function\n",
    "losses = list()\n",
    "model = SimpleModel().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "num_epochs = 30\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a733a0680ebd4f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T16:27:00.659946200Z",
     "start_time": "2023-11-09T16:27:00.647820700Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_it():\n",
    "    \"\"\"\n",
    "    Plot the training loss over epochs\n",
    "    \"\"\"\n",
    "    print(losses)\n",
    "    plt.plot(np.arange(len(losses)) + 1, losses, label=\"Training Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Training Loss Over Epochs\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75c8e7a97eb7d6df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T16:27:04.123331500Z",
     "start_time": "2023-11-09T16:27:00.652434700Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/30:  27%|â–ˆâ–ˆâ–‹       | 486/1768 [00:02<00:07, 179.24it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[12], line 14\u001B[0m\n\u001B[1;32m     12\u001B[0m loss \u001B[38;5;241m=\u001B[39m criterion(outputs, batch_y)\n\u001B[1;32m     13\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[0;32m---> 14\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m     15\u001B[0m total_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39mitem()\n\u001B[1;32m     16\u001B[0m temp\u001B[38;5;241m.\u001B[39mappend(loss\u001B[38;5;241m.\u001B[39mitem())\n",
      "File \u001B[0;32m~/miniconda3/envs/Diabetes/lib/python3.11/site-packages/torch/optim/optimizer.py:373\u001B[0m, in \u001B[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    368\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    369\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[1;32m    370\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresult\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    371\u001B[0m             )\n\u001B[0;32m--> 373\u001B[0m out \u001B[38;5;241m=\u001B[39m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    374\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_optimizer_step_code()\n\u001B[1;32m    376\u001B[0m \u001B[38;5;66;03m# call optimizer step post hooks\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/Diabetes/lib/python3.11/site-packages/torch/optim/optimizer.py:76\u001B[0m, in \u001B[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m     74\u001B[0m     torch\u001B[38;5;241m.\u001B[39mset_grad_enabled(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdefaults[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdifferentiable\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m     75\u001B[0m     torch\u001B[38;5;241m.\u001B[39m_dynamo\u001B[38;5;241m.\u001B[39mgraph_break()\n\u001B[0;32m---> 76\u001B[0m     ret \u001B[38;5;241m=\u001B[39m func(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m     77\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     78\u001B[0m     torch\u001B[38;5;241m.\u001B[39m_dynamo\u001B[38;5;241m.\u001B[39mgraph_break()\n",
      "File \u001B[0;32m~/miniconda3/envs/Diabetes/lib/python3.11/site-packages/torch/optim/adam.py:163\u001B[0m, in \u001B[0;36mAdam.step\u001B[0;34m(self, closure)\u001B[0m\n\u001B[1;32m    152\u001B[0m     beta1, beta2 \u001B[38;5;241m=\u001B[39m group[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbetas\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m    154\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_init_group(\n\u001B[1;32m    155\u001B[0m         group,\n\u001B[1;32m    156\u001B[0m         params_with_grad,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    160\u001B[0m         max_exp_avg_sqs,\n\u001B[1;32m    161\u001B[0m         state_steps)\n\u001B[0;32m--> 163\u001B[0m     adam(\n\u001B[1;32m    164\u001B[0m         params_with_grad,\n\u001B[1;32m    165\u001B[0m         grads,\n\u001B[1;32m    166\u001B[0m         exp_avgs,\n\u001B[1;32m    167\u001B[0m         exp_avg_sqs,\n\u001B[1;32m    168\u001B[0m         max_exp_avg_sqs,\n\u001B[1;32m    169\u001B[0m         state_steps,\n\u001B[1;32m    170\u001B[0m         amsgrad\u001B[38;5;241m=\u001B[39mgroup[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mamsgrad\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[1;32m    171\u001B[0m         beta1\u001B[38;5;241m=\u001B[39mbeta1,\n\u001B[1;32m    172\u001B[0m         beta2\u001B[38;5;241m=\u001B[39mbeta2,\n\u001B[1;32m    173\u001B[0m         lr\u001B[38;5;241m=\u001B[39mgroup[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlr\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[1;32m    174\u001B[0m         weight_decay\u001B[38;5;241m=\u001B[39mgroup[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mweight_decay\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[1;32m    175\u001B[0m         eps\u001B[38;5;241m=\u001B[39mgroup[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124meps\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[1;32m    176\u001B[0m         maximize\u001B[38;5;241m=\u001B[39mgroup[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmaximize\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[1;32m    177\u001B[0m         foreach\u001B[38;5;241m=\u001B[39mgroup[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mforeach\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[1;32m    178\u001B[0m         capturable\u001B[38;5;241m=\u001B[39mgroup[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcapturable\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[1;32m    179\u001B[0m         differentiable\u001B[38;5;241m=\u001B[39mgroup[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdifferentiable\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[1;32m    180\u001B[0m         fused\u001B[38;5;241m=\u001B[39mgroup[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfused\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[1;32m    181\u001B[0m         grad_scale\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgrad_scale\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m),\n\u001B[1;32m    182\u001B[0m         found_inf\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfound_inf\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m),\n\u001B[1;32m    183\u001B[0m     )\n\u001B[1;32m    185\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m loss\n",
      "File \u001B[0;32m~/miniconda3/envs/Diabetes/lib/python3.11/site-packages/torch/optim/adam.py:311\u001B[0m, in \u001B[0;36madam\u001B[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001B[0m\n\u001B[1;32m    308\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    309\u001B[0m     func \u001B[38;5;241m=\u001B[39m _single_tensor_adam\n\u001B[0;32m--> 311\u001B[0m func(params,\n\u001B[1;32m    312\u001B[0m      grads,\n\u001B[1;32m    313\u001B[0m      exp_avgs,\n\u001B[1;32m    314\u001B[0m      exp_avg_sqs,\n\u001B[1;32m    315\u001B[0m      max_exp_avg_sqs,\n\u001B[1;32m    316\u001B[0m      state_steps,\n\u001B[1;32m    317\u001B[0m      amsgrad\u001B[38;5;241m=\u001B[39mamsgrad,\n\u001B[1;32m    318\u001B[0m      beta1\u001B[38;5;241m=\u001B[39mbeta1,\n\u001B[1;32m    319\u001B[0m      beta2\u001B[38;5;241m=\u001B[39mbeta2,\n\u001B[1;32m    320\u001B[0m      lr\u001B[38;5;241m=\u001B[39mlr,\n\u001B[1;32m    321\u001B[0m      weight_decay\u001B[38;5;241m=\u001B[39mweight_decay,\n\u001B[1;32m    322\u001B[0m      eps\u001B[38;5;241m=\u001B[39meps,\n\u001B[1;32m    323\u001B[0m      maximize\u001B[38;5;241m=\u001B[39mmaximize,\n\u001B[1;32m    324\u001B[0m      capturable\u001B[38;5;241m=\u001B[39mcapturable,\n\u001B[1;32m    325\u001B[0m      differentiable\u001B[38;5;241m=\u001B[39mdifferentiable,\n\u001B[1;32m    326\u001B[0m      grad_scale\u001B[38;5;241m=\u001B[39mgrad_scale,\n\u001B[1;32m    327\u001B[0m      found_inf\u001B[38;5;241m=\u001B[39mfound_inf)\n",
      "File \u001B[0;32m~/miniconda3/envs/Diabetes/lib/python3.11/site-packages/torch/optim/adam.py:432\u001B[0m, in \u001B[0;36m_single_tensor_adam\u001B[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001B[0m\n\u001B[1;32m    430\u001B[0m         denom \u001B[38;5;241m=\u001B[39m (max_exp_avg_sqs[i]\u001B[38;5;241m.\u001B[39msqrt() \u001B[38;5;241m/\u001B[39m bias_correction2_sqrt)\u001B[38;5;241m.\u001B[39madd_(eps)\n\u001B[1;32m    431\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 432\u001B[0m         denom \u001B[38;5;241m=\u001B[39m (exp_avg_sq\u001B[38;5;241m.\u001B[39msqrt() \u001B[38;5;241m/\u001B[39m bias_correction2_sqrt)\u001B[38;5;241m.\u001B[39madd_(eps)\n\u001B[1;32m    434\u001B[0m     param\u001B[38;5;241m.\u001B[39maddcdiv_(exp_avg, denom, value\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39mstep_size)\n\u001B[1;32m    436\u001B[0m \u001B[38;5;66;03m# Lastly, switch back to complex view\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "temp = list()\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    temp.clear()\n",
    "    for batch_X, batch_y in tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{num_epochs}\"):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        temp.append(loss.item())\n",
    "    losses.append(np.mean(temp))\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Avg Loss: {avg_loss:.4f}\")\n",
    "    plot_it()\n",
    "    if epoch % 5 == 0:\n",
    "        torch.save(model, f\"model{epoch // 5}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cdaafe8877a22715",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T16:27:07.401399100Z",
     "start_time": "2023-11-09T16:27:06.933603700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7478\n"
     ]
    }
   ],
   "source": [
    "# Plot the training loss over epochs\n",
    "plot_it()\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(X_test_tensor)\n",
    "    predicted_labels = np.argmax(outputs.cpu(), axis=1)\n",
    "    accuracy = np.mean(predicted_labels.numpy() == y_test.to_numpy())\n",
    "    print(f\"Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc8fa251e83c32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "torch.save(model, \"model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3c368b42dea022d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T16:27:19.778860100Z",
     "start_time": "2023-11-09T16:27:19.714289400Z"
    }
   },
   "outputs": [],
   "source": [
    "model = torch.load(\"model3.pt\", map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a89ece5309663ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T16:27:13.842736600Z",
     "start_time": "2023-11-09T16:27:13.546361800Z"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[15], line 4\u001B[0m\n\u001B[1;32m      2\u001B[0m dict1 \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m16\u001B[39m):\n\u001B[0;32m----> 4\u001B[0m     model \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mload(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.pt\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      5\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[1;32m      6\u001B[0m         outputs \u001B[38;5;241m=\u001B[39m model(X_test_tensor)\n",
      "File \u001B[0;32m~/miniconda3/envs/Diabetes/lib/python3.11/site-packages/torch/serialization.py:1014\u001B[0m, in \u001B[0;36mload\u001B[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001B[0m\n\u001B[1;32m   1012\u001B[0m             \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m   1013\u001B[0m                 \u001B[38;5;28;01mraise\u001B[39;00m pickle\u001B[38;5;241m.\u001B[39mUnpicklingError(UNSAFE_MESSAGE \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(e)) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m-> 1014\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m _load(opened_zipfile,\n\u001B[1;32m   1015\u001B[0m                      map_location,\n\u001B[1;32m   1016\u001B[0m                      pickle_module,\n\u001B[1;32m   1017\u001B[0m                      overall_storage\u001B[38;5;241m=\u001B[39moverall_storage,\n\u001B[1;32m   1018\u001B[0m                      \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpickle_load_args)\n\u001B[1;32m   1019\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m mmap:\n\u001B[1;32m   1020\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmmap can only be used with files saved with \u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   1021\u001B[0m                        \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`torch.save(_use_new_zipfile_serialization=True), \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1022\u001B[0m                        \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mplease torch.save your checkpoint with this option in order to use mmap.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/miniconda3/envs/Diabetes/lib/python3.11/site-packages/torch/serialization.py:1422\u001B[0m, in \u001B[0;36m_load\u001B[0;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001B[0m\n\u001B[1;32m   1420\u001B[0m unpickler \u001B[38;5;241m=\u001B[39m UnpicklerWrapper(data_file, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpickle_load_args)\n\u001B[1;32m   1421\u001B[0m unpickler\u001B[38;5;241m.\u001B[39mpersistent_load \u001B[38;5;241m=\u001B[39m persistent_load\n\u001B[0;32m-> 1422\u001B[0m result \u001B[38;5;241m=\u001B[39m unpickler\u001B[38;5;241m.\u001B[39mload()\n\u001B[1;32m   1424\u001B[0m torch\u001B[38;5;241m.\u001B[39m_utils\u001B[38;5;241m.\u001B[39m_validate_loaded_sparse_tensors()\n\u001B[1;32m   1425\u001B[0m torch\u001B[38;5;241m.\u001B[39m_C\u001B[38;5;241m.\u001B[39m_log_api_usage_metadata(\n\u001B[1;32m   1426\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtorch.load.metadata\u001B[39m\u001B[38;5;124m\"\u001B[39m, {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mserialization_id\u001B[39m\u001B[38;5;124m\"\u001B[39m: zip_file\u001B[38;5;241m.\u001B[39mserialization_id()}\n\u001B[1;32m   1427\u001B[0m )\n",
      "File \u001B[0;32m~/miniconda3/envs/Diabetes/lib/python3.11/site-packages/torch/serialization.py:1392\u001B[0m, in \u001B[0;36m_load.<locals>.persistent_load\u001B[0;34m(saved_id)\u001B[0m\n\u001B[1;32m   1390\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1391\u001B[0m     nbytes \u001B[38;5;241m=\u001B[39m numel \u001B[38;5;241m*\u001B[39m torch\u001B[38;5;241m.\u001B[39m_utils\u001B[38;5;241m.\u001B[39m_element_size(dtype)\n\u001B[0;32m-> 1392\u001B[0m     typed_storage \u001B[38;5;241m=\u001B[39m load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))\n\u001B[1;32m   1394\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m typed_storage\n",
      "File \u001B[0;32m~/miniconda3/envs/Diabetes/lib/python3.11/site-packages/torch/serialization.py:1366\u001B[0m, in \u001B[0;36m_load.<locals>.load_tensor\u001B[0;34m(dtype, numel, key, location)\u001B[0m\n\u001B[1;32m   1361\u001B[0m         storage\u001B[38;5;241m.\u001B[39mbyteswap(dtype)\n\u001B[1;32m   1363\u001B[0m \u001B[38;5;66;03m# TODO: Once we decide to break serialization FC, we can\u001B[39;00m\n\u001B[1;32m   1364\u001B[0m \u001B[38;5;66;03m# stop wrapping with TypedStorage\u001B[39;00m\n\u001B[1;32m   1365\u001B[0m typed_storage \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mstorage\u001B[38;5;241m.\u001B[39mTypedStorage(\n\u001B[0;32m-> 1366\u001B[0m     wrap_storage\u001B[38;5;241m=\u001B[39mrestore_location(storage, location),\n\u001B[1;32m   1367\u001B[0m     dtype\u001B[38;5;241m=\u001B[39mdtype,\n\u001B[1;32m   1368\u001B[0m     _internal\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m   1370\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m typed_storage\u001B[38;5;241m.\u001B[39m_data_ptr() \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m   1371\u001B[0m     loaded_storages[key] \u001B[38;5;241m=\u001B[39m typed_storage\n",
      "File \u001B[0;32m~/miniconda3/envs/Diabetes/lib/python3.11/site-packages/torch/serialization.py:381\u001B[0m, in \u001B[0;36mdefault_restore_location\u001B[0;34m(storage, location)\u001B[0m\n\u001B[1;32m    379\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdefault_restore_location\u001B[39m(storage, location):\n\u001B[1;32m    380\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m _, _, fn \u001B[38;5;129;01min\u001B[39;00m _package_registry:\n\u001B[0;32m--> 381\u001B[0m         result \u001B[38;5;241m=\u001B[39m fn(storage, location)\n\u001B[1;32m    382\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m result \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    383\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[0;32m~/miniconda3/envs/Diabetes/lib/python3.11/site-packages/torch/serialization.py:274\u001B[0m, in \u001B[0;36m_cuda_deserialize\u001B[0;34m(obj, location)\u001B[0m\n\u001B[1;32m    272\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_cuda_deserialize\u001B[39m(obj, location):\n\u001B[1;32m    273\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m location\u001B[38;5;241m.\u001B[39mstartswith(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcuda\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[0;32m--> 274\u001B[0m         device \u001B[38;5;241m=\u001B[39m validate_cuda_device(location)\n\u001B[1;32m    275\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(obj, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_torch_load_uninitialized\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[1;32m    276\u001B[0m             \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mdevice(device):\n",
      "File \u001B[0;32m~/miniconda3/envs/Diabetes/lib/python3.11/site-packages/torch/serialization.py:258\u001B[0m, in \u001B[0;36mvalidate_cuda_device\u001B[0;34m(location)\u001B[0m\n\u001B[1;32m    255\u001B[0m device \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39m_utils\u001B[38;5;241m.\u001B[39m_get_device_index(location, \u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m    257\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mis_available():\n\u001B[0;32m--> 258\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAttempting to deserialize object on a CUDA \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    259\u001B[0m                        \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdevice but torch.cuda.is_available() is False. \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    260\u001B[0m                        \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mIf you are running on a CPU-only machine, \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    261\u001B[0m                        \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mplease use torch.load with map_location=torch.device(\u001B[39m\u001B[38;5;130;01m\\'\u001B[39;00m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;130;01m\\'\u001B[39;00m\u001B[38;5;124m) \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    262\u001B[0m                        \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mto map your storages to the CPU.\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    263\u001B[0m device_count \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mdevice_count()\n\u001B[1;32m    264\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m device \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m device_count:\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
     ]
    }
   ],
   "source": [
    "# test the model\n",
    "dict1 = {}\n",
    "for i in range(16):\n",
    "    model = torch.load(f\"model{i}.pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X_test_tensor)\n",
    "        predicted_labels = np.argmax(outputs.cpu(), axis=1)\n",
    "        accuracy = np.mean(predicted_labels.numpy() == y_test.to_numpy())\n",
    "        print(f\"Test Accuracy{i}: {accuracy:.4f}\")\n",
    "        dict1[f\"model{i}.pt\"] = f\"{accuracy:.4f}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7522\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(X_test_tensor)\n",
    "    predicted_labels = np.argmax(outputs.cpu(), axis=1)\n",
    "    accuracy = np.mean(predicted_labels.numpy() == y_test.to_numpy())\n",
    "    print(f\"Test Accuracy: {accuracy:.4f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-09T16:27:22.703386100Z",
     "start_time": "2023-11-09T16:27:22.525971300Z"
    }
   },
   "id": "ad24b75fb3f2b17e"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b8fc0b36fe503f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T16:01:09.890783800Z",
     "start_time": "2023-11-09T15:57:29.613859200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Input:\n",
      "[ 1  1  1 26  0  0  0  1  1  1  0  1  0  3 30  3  0  1  0  6  8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1921/3512270828.py:8: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1695392035891/work/torch/csrc/utils/tensor_new.cpp:261.)\n",
      "  user_input = torch.tensor([user_input], dtype=torch.float32).to(device)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (21x1 and 21x64)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[16], line 9\u001B[0m\n\u001B[1;32m      7\u001B[0m user_input \u001B[38;5;241m=\u001B[39m scaler\u001B[38;5;241m.\u001B[39mfit_transform(user_input\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m))\n\u001B[1;32m      8\u001B[0m user_input \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor([user_input], dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mfloat32)\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m----> 9\u001B[0m out \u001B[38;5;241m=\u001B[39m model(user_input)\n\u001B[1;32m     10\u001B[0m temp \u001B[38;5;241m=\u001B[39m out[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m-\u001B[39m out[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m     11\u001B[0m temp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mstr\u001B[39m(temp)\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m,\u001B[39m\u001B[38;5;124m'\u001B[39m)[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m(\u001B[39m\u001B[38;5;124m'\u001B[39m)[\u001B[38;5;241m1\u001B[39m]\n",
      "File \u001B[0;32m~/miniconda3/envs/Diabetes/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/miniconda3/envs/Diabetes/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[7], line 16\u001B[0m, in \u001B[0;36mSimpleModel.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[0;32m---> 16\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfc1(x)\n\u001B[1;32m     17\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrelu(x)\n\u001B[1;32m     18\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfc2(x)\n",
      "File \u001B[0;32m~/miniconda3/envs/Diabetes/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/miniconda3/envs/Diabetes/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/Diabetes/lib/python3.11/site-packages/torch/nn/modules/linear.py:114\u001B[0m, in \u001B[0;36mLinear.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 114\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mlinear(\u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweight, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbias)\n",
      "\u001B[0;31mRuntimeError\u001B[0m: mat1 and mat2 shapes cannot be multiplied (21x1 and 21x64)"
     ]
    }
   ],
   "source": [
    "from Get_data import get_user_input  # custom function to get user input\n",
    "\n",
    "user_input = get_user_input()\n",
    "print(\"User Input:\")\n",
    "backup = user_input\n",
    "print(user_input)\n",
    "user_input = scaler.fit_transform(user_input.reshape(-1, 1))\n",
    "user_input = torch.tensor([user_input], dtype=torch.float32).to(device)\n",
    "out = model(user_input)\n",
    "temp = out[0][0] - out[0][1]\n",
    "temp = str(temp).split(',')[0].split('(')[1]\n",
    "if out[0][0] > out[0][1]:\n",
    "    print(\"You don't have diabetes probability: \", (1 - float(temp)) * 100)\n",
    "else:\n",
    "    print(\"You have diabetes probability: \", float(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9dc2030d9c82f6dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T16:37:26.398684200Z",
     "start_time": "2023-11-09T16:37:26.333984Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9822, 0.0178]], grad_fn=<SoftmaxBackward0>)\n",
      "You don't have diabetes probability:  3.5599999999999965\n"
     ]
    }
   ],
   "source": [
    "user_input = [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 3, 1, 3, 0, 1, 0, 6, 8]\n",
    "user_input = torch.tensor([user_input], dtype=torch.float32).to(device)\n",
    "out = model(user_input)\n",
    "temp = out[0][0] - out[0][1]\n",
    "temp = str(temp).split(',')[0].split('(')[1]\n",
    "print(out)\n",
    "if out[0][0] > out[0][1]:\n",
    "    print(\"You don't have diabetes probability: \", (1 - float(temp)) * 100)\n",
    "else:\n",
    "    print(\"You have diabetes probability: \",  abs(float(temp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "user_input = backup\n",
    "user_input = torch.tensor(np.array([user_input], dtype=np.float32), dtype=torch.float32).to(device)\n",
    "model(user_input)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b817d72b1f6bf74a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "user_input = backup\n",
    "#user_input = scaler.fit_transform(user_input.reshape(-1, 1))\n",
    "#user_input = np.transpose(user_input)[0]\n",
    "user_input = torch.tensor([user_input], dtype=torch.float32).to(device)\n",
    "out = model(user_input)\n",
    "if out[0][0] > out[0][1]:\n",
    "    print(\"You don't have diabetes\")\n",
    "else:\n",
    "    print(\"You have diabetes\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "999be0cd83855c9a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "user_input = [1, 1, 1, 30, 0, 0, 0, 1, 1, 1, 0, 1, 0, 3, 30, 0, 0, 1, 1, 4, 1]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "47a0b2f29b9cb123"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "user_input = [1, 1, 1, 30, 0, 0, 0, 1, 1, 1, 0, 1, 0, 3, 30, 0, 0, 1, 1, 4, 1]\n",
    "user_input = np.array(user_input)\n",
    "user_input = torch.tensor(\n",
    "    scaler.fit_transform(pd.DataFrame([user_input], columns=X.columns))\n",
    ").to(device)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "38dc180c4a7c5ea7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "backup = np.array(user_input, dtype=np.float32)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "763dfc3fe8b04f76"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "backup = [1, 1, 1, 30, 0, 0, 0, 1, 1, 1, 0, 1, 0, 3, 30, 0, 0, 1, 1, 4, 1]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e4e9c77a46c0902f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "out"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dd7db05b63a0110c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(data)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1205e7cdbf2b0579"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import hiddenlayer as hl\n",
    "\n",
    "model = model.to('cpu')\n",
    "print(model.parameters)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3895ce7a6a192469"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
